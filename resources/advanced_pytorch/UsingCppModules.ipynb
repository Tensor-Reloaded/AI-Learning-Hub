{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/advanced_pytorch/UsingCppModules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-Egajx6dH5y"
      },
      "source": [
        "# Using CPP modules\n",
        "\n",
        "Writing parts of a Deep Learning pipeline in C++ unlocks many oportunities for optimizing speed and resource consumption.\n",
        "\n",
        "PyTorch provides a very nice and easy to use interface for writing a module in C++, compiling it and using it in Python.\n",
        "\n",
        "In this lesson we learn how to implement the Macro F1 Score in C++ and use it in Python. However, the real performance of C++ is seen when moving even more complex Python based processing to C++."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbUzriuXycKC"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we get the `optimized_f1_score` module."
      ],
      "metadata": {
        "id": "h2Dc64jdRNgn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b2biFvtWycKD"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "if not os.path.isdir(\"optimized_f1_score\"):\n",
        "    subprocess.run([\"git\", \"clone\", \"https://www.github.com/Tensor-Reloaded/AI-Learning-Hub\"], check=True)\n",
        "    shutil.copytree(\"AI-Learning-Hub/resources/advanced_pytorch/optimized_f1_score\", \"optimized_f1_score\")\n",
        "    shutil.rmtree(\"AI-Learning-Hub\", ignore_errors=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the content of each file. First we have the Macro F1 Score implemented in Python."
      ],
      "metadata": {
        "id": "r8CB94AiRv1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pygmentize -g optimized_f1_score/f1_macro_py.py"
      ],
      "metadata": {
        "id": "7jvAI6jvR98O",
        "outputId": "abb89ac1-4e3b-42d3-f50f-8f7e437f055f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mf1_score\u001b[39;49;00m(x: torch.BoolTensor, y: torch.BoolTensor) -> \u001b[36mfloat\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "    x_sum = x.sum()\u001b[37m\u001b[39;49;00m\n",
            "    y_sum = y.sum()\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mif\u001b[39;49;00m x_sum == \u001b[34m0\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m y_sum == \u001b[34m0\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mif\u001b[39;49;00m x_sum == \u001b[34m0\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m y_sum == \u001b[34m0\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "            \u001b[34mreturn\u001b[39;49;00m \u001b[34m1.0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mreturn\u001b[39;49;00m \u001b[34m0.0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mreturn\u001b[39;49;00m \u001b[34m2\u001b[39;49;00m * (x & y).sum() / (x_sum + y_sum)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mf1_macro\u001b[39;49;00m(x: torch.Tensor, y: torch.Tensor, classes: \u001b[36mint\u001b[39;49;00m) -> \u001b[36mfloat\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "    result = \u001b[34m0.0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mfor\u001b[39;49;00m c \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(classes):\u001b[37m\u001b[39;49;00m\n",
            "        result += f1_score(x == c, y == c)\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mreturn\u001b[39;49;00m result / classes\u001b[37m\u001b[39;49;00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we have the same function implemented in C++."
      ],
      "metadata": {
        "id": "qqxz-cX7SErF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pygmentize -g optimized_f1_score/f1_macro_cpp.cpp"
      ],
      "metadata": {
        "id": "ywAPTgqcSSM0",
        "outputId": "99ca17d9-76fe-409c-912e-dbac38ac6cad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m#\u001b[39;49;00m\u001b[36minclude\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[37m<torch/extension.h>\u001b[39;49;00m\u001b[36m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[36mdouble\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mf1_score\u001b[39;49;00m(torch::Tensor\u001b[37m \u001b[39;49;00mx,\u001b[37m \u001b[39;49;00mtorch::Tensor\u001b[37m \u001b[39;49;00my)\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[34mauto\u001b[39;49;00m\u001b[37m \u001b[39;49;00mx_sum\u001b[37m \u001b[39;49;00m=\u001b[37m \u001b[39;49;00mx.sum().item<\u001b[36mdouble\u001b[39;49;00m>();\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[34mauto\u001b[39;49;00m\u001b[37m \u001b[39;49;00my_sum\u001b[37m \u001b[39;49;00m=\u001b[37m \u001b[39;49;00my.sum().item<\u001b[36mdouble\u001b[39;49;00m>();\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[34mif\u001b[39;49;00m\u001b[37m \u001b[39;49;00m(x_sum\u001b[37m \u001b[39;49;00m==\u001b[37m \u001b[39;49;00m\u001b[34m0.0\u001b[39;49;00m\u001b[37m \u001b[39;49;00m||\u001b[37m \u001b[39;49;00my_sum\u001b[37m \u001b[39;49;00m==\u001b[37m \u001b[39;49;00m\u001b[34m0.0\u001b[39;49;00m)\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m        \u001b[39;49;00m\u001b[34mif\u001b[39;49;00m\u001b[37m \u001b[39;49;00m(x_sum\u001b[37m \u001b[39;49;00m==\u001b[37m \u001b[39;49;00m\u001b[34m0.0\u001b[39;49;00m\u001b[37m \u001b[39;49;00m&&\u001b[37m \u001b[39;49;00my_sum\u001b[37m \u001b[39;49;00m==\u001b[37m \u001b[39;49;00m\u001b[34m0.0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m            \u001b[39;49;00m\u001b[34mreturn\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34m1.0\u001b[39;49;00m;\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m        \u001b[39;49;00m\u001b[34mreturn\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34m0.0\u001b[39;49;00m;\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[34mauto\u001b[39;49;00m\u001b[37m \u001b[39;49;00mintersection\u001b[37m \u001b[39;49;00m=\u001b[37m \u001b[39;49;00m(x\u001b[37m \u001b[39;49;00m&\u001b[37m \u001b[39;49;00my).sum().item<\u001b[36mdouble\u001b[39;49;00m>();\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[34mreturn\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34m2.0\u001b[39;49;00m\u001b[37m \u001b[39;49;00m*\u001b[37m \u001b[39;49;00mintersection\u001b[37m \u001b[39;49;00m/\u001b[37m \u001b[39;49;00m(x_sum\u001b[37m \u001b[39;49;00m+\u001b[37m \u001b[39;49;00my_sum);\u001b[37m\u001b[39;49;00m\n",
            "}\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[36mdouble\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mf1_macro\u001b[39;49;00m(torch::Tensor\u001b[37m \u001b[39;49;00mx,\u001b[37m \u001b[39;49;00mtorch::Tensor\u001b[37m \u001b[39;49;00my,\u001b[37m \u001b[39;49;00m\u001b[36mint\u001b[39;49;00m\u001b[37m \u001b[39;49;00mclasses)\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[37m// You can disable the checks if you own this function. Never do this if you can't control the input.\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00mTORCH_CHECK(x.sizes()\u001b[37m \u001b[39;49;00m==\u001b[37m \u001b[39;49;00my.sizes(),\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInput tensors must have the same shape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m);\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00mTORCH_CHECK(x.device()\u001b[37m \u001b[39;49;00m==\u001b[37m \u001b[39;49;00my.device(),\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mInput tensors must be on the same device\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m);\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[36mdouble\u001b[39;49;00m\u001b[37m \u001b[39;49;00mresult\u001b[37m \u001b[39;49;00m=\u001b[37m \u001b[39;49;00m\u001b[34m0.0\u001b[39;49;00m;\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[34mfor\u001b[39;49;00m\u001b[37m \u001b[39;49;00m(\u001b[36mint\u001b[39;49;00m\u001b[37m \u001b[39;49;00mc\u001b[37m \u001b[39;49;00m=\u001b[37m \u001b[39;49;00m\u001b[34m0\u001b[39;49;00m;\u001b[37m \u001b[39;49;00mc\u001b[37m \u001b[39;49;00m<\u001b[37m \u001b[39;49;00mclasses;\u001b[37m \u001b[39;49;00m++c)\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m        \u001b[39;49;00m\u001b[34mauto\u001b[39;49;00m\u001b[37m \u001b[39;49;00mx_mask\u001b[37m \u001b[39;49;00m=\u001b[37m \u001b[39;49;00m(x\u001b[37m \u001b[39;49;00m==\u001b[37m \u001b[39;49;00mc);\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m        \u001b[39;49;00m\u001b[34mauto\u001b[39;49;00m\u001b[37m \u001b[39;49;00my_mask\u001b[37m \u001b[39;49;00m=\u001b[37m \u001b[39;49;00m(y\u001b[37m \u001b[39;49;00m==\u001b[37m \u001b[39;49;00mc);\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m        \u001b[39;49;00mresult\u001b[37m \u001b[39;49;00m+=\u001b[37m \u001b[39;49;00mf1_score(x_mask,\u001b[37m \u001b[39;49;00my_mask);\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00m\u001b[34mreturn\u001b[39;49;00m\u001b[37m \u001b[39;49;00mresult\u001b[37m \u001b[39;49;00m/\u001b[37m \u001b[39;49;00mclasses;\u001b[37m\u001b[39;49;00m\n",
            "}\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m// Bind functions to Python\u001b[39;49;00m\n",
            "PYBIND11_MODULE(TORCH_EXTENSION_NAME,\u001b[37m \u001b[39;49;00mm)\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00mm.def(\u001b[33m\"\u001b[39;49;00m\u001b[33mf1_score\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m&f1_score,\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mF1 score for one class (bool tensors)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m);\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m    \u001b[39;49;00mm.def(\u001b[33m\"\u001b[39;49;00m\u001b[33mf1_macro\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m \u001b[39;49;00m&f1_macro,\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mMacro F1 score (int tensors)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m);\u001b[37m\u001b[39;49;00m\n",
            "}\u001b[37m\u001b[39;49;00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you can read the code above, you can see that the C++ implementation of `f1_macro` and `f1_score` is very similar to the Python implementation.\n",
        "\n",
        "Whenever we write a C++ module, we need to include the torch extensions (`#include <torch/extension.h>`) and we need to use the `PYBIND11_MODULE` macro to bind the functions implemented in C++ to Python, allowing them to be called just like regular Python functions.\n",
        "\n",
        "To build the C++ code, we need a `setup.py` file just like we would build any Python library from source."
      ],
      "metadata": {
        "id": "LOpVgW7hSWNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pygmentize -g optimized_f1_score/setup.py"
      ],
      "metadata": {
        "id": "42aVDy8ATJj7",
        "outputId": "d8455ba8-7e35-46cb-dcbb-623fed19bb5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36msetuptools\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m setup\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcpp_extension\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m CppExtension, BuildExtension\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mget_extra_compile_args\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mif\u001b[39;49;00m os.name == \u001b[33m\"\u001b[39;49;00m\u001b[33mnt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mreturn\u001b[39;49;00m {\u001b[37m\u001b[39;49;00m\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33mmsvc\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: [\u001b[33m\"\u001b[39;49;00m\u001b[33m/std:c++20\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m/O2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m/DNDEBUG\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
            "                     \u001b[37m# \"/arch:AVX2\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "                     ],\u001b[37m\u001b[39;49;00m\n",
            "        }\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mreturn\u001b[39;49;00m {\u001b[37m\u001b[39;49;00m\n",
            "            \u001b[33m\"\u001b[39;49;00m\u001b[33mcxx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: [\u001b[33m\"\u001b[39;49;00m\u001b[33m-std=c++20\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m-O3\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m-DNDEBUG\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
            "                    \u001b[37m# \"-mavx2\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "                    ],\u001b[37m\u001b[39;49;00m\n",
            "        }\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "    setup(\u001b[37m\u001b[39;49;00m\n",
            "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33moptimized_f1_score\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
            "        ext_modules=[\u001b[37m\u001b[39;49;00m\n",
            "            CppExtension(\u001b[37m\u001b[39;49;00m\n",
            "                \u001b[33m\"\u001b[39;49;00m\u001b[33mf1_macro_cpp\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
            "                [\u001b[33m\"\u001b[39;49;00m\u001b[33mf1_macro_cpp.cpp\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
            "                extra_compile_args=get_extra_compile_args(),\u001b[37m\u001b[39;49;00m\n",
            "                define_macros=[\u001b[37m\u001b[39;49;00m\n",
            "                    (\u001b[33m\"\u001b[39;49;00m\u001b[33mARCH_DEFAULT\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[34mNone\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "                ],\u001b[37m\u001b[39;49;00m\n",
            "            ),\u001b[37m\u001b[39;49;00m\n",
            "        ],\u001b[37m\u001b[39;49;00m\n",
            "        cmdclass={\u001b[33m\"\u001b[39;49;00m\u001b[33mbuild_ext\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: BuildExtension},\u001b[37m\u001b[39;49;00m\n",
            "    )\u001b[37m\u001b[39;49;00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above you have the `setup.py` file. In this file you can set compile options that can speed the C++ code using vectorization depending on your architecture.\n",
        "For example, I can use `/arch:AVX2` or `-mavx2` to tell the compiler that it can use 256-bit SIMD instructions (see the commented out code).\n",
        "\n",
        "On most non-Mac modern hardware, using AVX2 is a great way of speeding up your tensor computations using vectorized instructions.\n",
        "Depending on your hardware, you can also use `AVX`, `SSE`, `SSE2`, and so on.\n",
        "\n",
        "You can also enable fused multiply add or fast math (if you know what you are doing)."
      ],
      "metadata": {
        "id": "inWBW-UBTV8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pygmentize -g optimized_f1_score/build.py"
      ],
      "metadata": {
        "id": "F61kUplRULpA",
        "outputId": "f6d5bc6b-55f1-4bee-fe13-ba77bcf861b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36msubprocess\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36mfilelock\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mbuild\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
            "    p_dir = os.path.dirname(\u001b[31m__file__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    lock_path = os.path.join(p_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33m.lock\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36moptimized_f1_score\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mf1_macro_cpp\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m f1_macro\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mImportError\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mwith\u001b[39;49;00m filelock.FileLock(lock_path):\u001b[37m\u001b[39;49;00m\n",
            "            \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mBuilding Optimized F1 Score\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "            try_build(p_dir)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mtry_build\u001b[39;49;00m(p_dir):\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "        setup_cmd = \u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mpython setup.py build_ext --inplace\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mif\u001b[39;49;00m os.name == \u001b[33m\"\u001b[39;49;00m\u001b[33mnt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "            setup_cmd = prepare_windows_build() + setup_cmd\u001b[37m\u001b[39;49;00m\n",
            "        subprocess.run(setup_cmd, shell=\u001b[34mTrue\u001b[39;49;00m, cwd=p_dir)\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mError during build. Please check logs. See \u001b[39;49;00m\u001b[33m{\u001b[39;49;00me\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone building\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mdef\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[32mprepare_windows_build\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
            "    activate_msvc = \u001b[33m\"\u001b[39;49;00m\u001b[33mC:\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33mProgram Files\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33mMicrosoft Visual Studio\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33m2022\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33mCommunity\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33mVC\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33mAuxiliary\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33mBuild\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33mvcvars64.bat\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mACTIVATE_MSVC\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[35min\u001b[39;49;00m os.environ:\u001b[37m\u001b[39;49;00m\n",
            "        activate_msvc = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mACTIVATE_MSVC\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m os.path.isfile(activate_msvc):\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mraise\u001b[39;49;00m \u001b[36mRuntimeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mMSCV must be activated, but \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mactivate_msvc\u001b[33m}\u001b[39;49;00m\u001b[33m file was not found. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "                           \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mEnsure that Microsoft Visual Studio is installed and set the ACTIVATE_MSVC \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
            "                           \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mto point to vcvars64.bat\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mreturn\u001b[39;49;00m \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mactivate_msvc\u001b[33m}\u001b[39;49;00m\u001b[33m\\\"\u001b[39;49;00m\u001b[33m && set DISTUTILS_USE_SDK=1 && \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The build file above allows us to dynamically build the C++ module as a Python library. We just need to have a compatible C++ compiler vizible in the path (which means that we have to activate MSVC on Windows)."
      ],
      "metadata": {
        "id": "a8dlAgmqUOYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pygmentize -g optimized_f1_score/__init__.py"
      ],
      "metadata": {
        "id": "iDWAQsWaUqzI",
        "outputId": "40793b53-3935-409e-c87a-ac1a19b7548e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36moptimized_f1_score\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mbuild\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m build\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36moptimized_f1_score\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mf1_macro_cpp\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m f1_macro\u001b[37m\u001b[39;49;00m\n",
            "\u001b[34mexcept\u001b[39;49;00m \u001b[36mImportError\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
            "        build()\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36moptimized_f1_score\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mf1_macro_cpp\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m f1_macro\u001b[37m\u001b[39;49;00m\n",
            "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mImportError\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mBuilding Optimized F1 Score failed. Using Fallback\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
            "        \u001b[34mfrom\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[04m\u001b[36moptimized_f1_score\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mf1_macro_py\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[34mimport\u001b[39;49;00m f1_macro\u001b[37m\u001b[39;49;00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how we implement dynamic building and importing of a C++ module, with a fallback that allows us to use the Python implementation if compilation failed."
      ],
      "metadata": {
        "id": "ObcoqaEeUtwo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6cL13rU8dK4k",
        "outputId": "c7aeee3d-1612-4115-c06f-6913e867b6d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Optimized F1 Score\n",
            "Done building\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from optimized_f1_score import f1_macro_cpp, f1_macro_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A_MHvyxpycKF"
      },
      "outputs": [],
      "source": [
        "num_classes = 100\n",
        "size = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "obLQ9-J-ycKH"
      },
      "outputs": [],
      "source": [
        "torch.random.manual_seed(3)\n",
        "x = torch.randint(0, num_classes, (size,))\n",
        "y = torch.randint(0, num_classes, (size,))\n",
        "x_cuda = x.cuda()\n",
        "y_cuda = y.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3IEnDJRJycKI",
        "outputId": "8bbada1c-59df-4f5f-c15f-6dbd78762849",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.2 ms ± 82.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "f1_macro_cpp.f1_macro(x, y, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DwQH9oeEycKJ",
        "outputId": "a64e2885-7a9e-465e-af45-d5e4ac98e855",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.87 ms ± 1.72 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "f1_macro_py.f1_macro(x, y, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6ii7DIS7ycKL",
        "outputId": "b76e1609-68c2-4352-fbae-0ecd48b14986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.3 ms ± 841 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "f1_macro_cpp.f1_macro(x_cuda, y_cuda, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tcsxnjY1ycKM",
        "outputId": "1fa0145f-06e4-436e-e636-9875d17a933b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18.5 ms ± 2.06 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "f1_macro_py.f1_macro(x_cuda, y_cuda, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the C++ module is faster than the Python implementation.\n",
        "And hey, we can also make our C++ code faster by releasing the GIL lock and using threads!\n",
        "\n",
        "Writing data processing pipelines in C++ can make your code 10x-100x faster or even more (if you know what are you doing)!\n",
        "\n",
        "The benefits of using C++ are mostly seen on CPU tensors. To speed up GPU computation even more, you usually need to implement custom CUDA kernels, which is not covered in this tutorial."
      ],
      "metadata": {
        "id": "ZBNfIzuxU8zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "yrYVmNFhN2OA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional resources:\n",
        "* Check the cppdocs, torch has a really nice library interfacing with C++: https://docs.pytorch.org/cppdocs/\n",
        "* Check the official PyTorch tutorial for custom C++ operators: https://docs.pytorch.org/tutorials/advanced/cpp_custom_ops.html\n",
        "* This is the official documentation for CppExtension: https://docs.pytorch.org/docs/stable/cpp_extension.html\n",
        "* This tutorial shows how to optimize the data processing pipeline with custom PyTorch operators: https://medium.com/data-science/how-to-optimize-your-dl-data-input-pipeline-with-a-custom-pytorch-operator-7f8ea2da5206"
      ],
      "metadata": {
        "id": "e0ulM2-fN4Ih"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiVkCtJgdH5z"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW74vX_KdH50"
      },
      "source": [
        "| All     | [advanced_pytorch/](https://github.com/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/advanced_pytorch) |\n",
        "|---------|-- |\n",
        "| Current | [Using Cpp Modules](https://github.com/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/advanced_pytorch/UsingCppModules.ipynb) |"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}