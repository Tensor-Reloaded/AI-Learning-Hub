{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/beginner_pytorch/06_data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvpaJ3XEDVrL"
      },
      "source": [
        "# 06. Simple Data Augmentation\n",
        "\n",
        "Start with the official documentation:\n",
        "\n",
        "1. https://docs.pytorch.org/vision/main/auto_examples/transforms/plot_transforms_getting_started.html\n",
        "2. https://docs.pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html\n",
        "\n",
        "After finishing and understanding the examples in the official documentation, proceed further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fKJbsSCDVrN"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.transforms.v2.functional import hflip\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWiF3h8_DVrO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"True\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-bv9ApuDVrO"
      },
      "outputs": [],
      "source": [
        "img_size = 224\n",
        "num_classes = 37"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BotD4eBFDVrO"
      },
      "outputs": [],
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, split, image_transforms):\n",
        "        self.data = OxfordIIITPet(\n",
        "            root=\"../data\",\n",
        "            download=True,\n",
        "            split=split,\n",
        "            target_types=(\"category\",),\n",
        "        )\n",
        "        self.image_transforms = image_transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        image, class_label = self.data[i]\n",
        "        image = self.image_transforms(image)\n",
        "        return image, class_label\n",
        "\n",
        "\n",
        "image_transforms_train = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.Resize([img_size, img_size]),\n",
        "    v2.RandomCrop([img_size, img_size], padding=12),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.AutoAugment(),\n",
        "])\n",
        "\n",
        "image_transforms_test = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.Resize([img_size, img_size]),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "])\n",
        "\n",
        "cutmix_or_mixup = v2.RandomChoice([\n",
        "    v2.CutMix(num_classes=num_classes),\n",
        "    v2.MixUp(num_classes=num_classes),\n",
        "])\n",
        "\n",
        "train_dataset = ClassificationDataset(\"trainval\", image_transforms_train)\n",
        "test_dataset = ClassificationDataset(\"test\", image_transforms_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=32, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc9jE4LdDVrP"
      },
      "source": [
        "## Automatic augmentation\n",
        "\n",
        "1\\. [AutoAugment: Learning Augmentation Policies from Data](https://arxiv.org/abs/1805.09501)\n",
        "```py\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "v2.AutoAugment(policy=v2.AutoAugmentPolicy.IMAGENET) (default)\n",
        "v2.AutoAugment(policy=v2.AutoAugmentPolicy.SVHN)\n",
        "v2.AutoAugment(policy=v2.AutoAugmentPolicy.CIFAR10)\n",
        "```\n",
        "2\\. [RandAugment: Practical automated data augmentation with a reduced search space](https://arxiv.org/abs/1909.13719L)\n",
        "```py\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "v2.RandAugment(num_ops=2, magnitude=8) (default)\n",
        "v2.RandAugment(num_ops=4, magnitude=4)\n",
        "v2.RandAugment(num_ops=3, magnitude=10)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBQPnSm0DVrP"
      },
      "outputs": [],
      "source": [
        "for images, labels in DataLoader(train_dataset, shuffle=False, batch_size=8):\n",
        "    break\n",
        "v2.functional.to_pil_image(torchvision.utils.make_grid(images, nrow=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA9j8nZnDVrP"
      },
      "outputs": [],
      "source": [
        "for images, labels in DataLoader(train_dataset, shuffle=False, batch_size=8):\n",
        "    break\n",
        "v2.functional.to_pil_image(torchvision.utils.make_grid(images, nrow=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-lM65umDVrP"
      },
      "source": [
        "### CutMix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gbEhmb8DVrQ"
      },
      "outputs": [],
      "source": [
        "for images, labels in DataLoader(train_dataset, shuffle=False, batch_size=8):\n",
        "    break\n",
        "images, labels  = v2.CutMix(num_classes=num_classes)(images, labels)\n",
        "v2.functional.to_pil_image(torchvision.utils.make_grid(images, nrow=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHy1g9AgDVrQ"
      },
      "outputs": [],
      "source": [
        "for images, labels in DataLoader(train_dataset, shuffle=True, batch_size=8):\n",
        "    break\n",
        "images, labels  = v2.CutMix(num_classes=num_classes)(images, labels)\n",
        "v2.functional.to_pil_image(torchvision.utils.make_grid(images, nrow=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1GHhFzlDVrR"
      },
      "source": [
        "Let's see what happens with the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YTOc5GUDVrR"
      },
      "outputs": [],
      "source": [
        "def draw_all(to_draw, labels):\n",
        "    size = num_classes // 4\n",
        "    for i in range(len(to_draw)):\n",
        "        plt.imshow(v2.functional.to_pil_image(to_draw[i]))\n",
        "        label = labels[i]\n",
        "        label = [round(x.item(), 4) for x in torch.atleast_1d(label)]\n",
        "        label = '\\n'.join([str(label[i * size: (i + 1) * size]) for i in range(4)])\n",
        "        plt.title(label)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "866oOGJnDVrR"
      },
      "outputs": [],
      "source": [
        "draw_all(images, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WBIFFs3DVrR"
      },
      "source": [
        "### MixUp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfPjG0BZDVrR"
      },
      "outputs": [],
      "source": [
        "for images, labels in DataLoader(train_dataset, shuffle=False, batch_size=8):\n",
        "    break\n",
        "images, labels  = v2.MixUp(num_classes=num_classes)(images, labels)\n",
        "v2.functional.to_pil_image(torchvision.utils.make_grid(images, nrow=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgMimTWtDVrR"
      },
      "outputs": [],
      "source": [
        "for images, labels in DataLoader(train_dataset, shuffle=True, batch_size=8):\n",
        "    break\n",
        "images, labels  = v2.MixUp(num_classes=num_classes)(images, labels)\n",
        "v2.functional.to_pil_image(torchvision.utils.make_grid(images, nrow=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-HEHDUFDVrS"
      },
      "outputs": [],
      "source": [
        "draw_all(images, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtT2LO1yDVrS"
      },
      "source": [
        "## Other Data Augmentation techniques\n",
        "\n",
        "The [Mozaic](https://arxiv.org/pdf/2004.12432) Data Augmentation.\n",
        "\n",
        "For Object detection & segmentation tasks, see https://github.com/albumentations-team/albumentations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v4_MmANDVrS"
      },
      "source": [
        "# Excercises\n",
        "\n",
        "1. Use data augmentation to achieve better results for MNIST. Try use flipping. Does it help?\n",
        "2. Implement a pipeline for CIFAR-10. Try to achieve better results!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bit_313",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}