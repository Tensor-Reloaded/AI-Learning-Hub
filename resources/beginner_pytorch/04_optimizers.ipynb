{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/beginner_pytorch/04_optimizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4CwWkzxCy5z"
      },
      "source": [
        "# 04. Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g-rs4CMUCy53"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "opA9a8sOCy55"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(\n",
        "            self,\n",
        "            model: nn.Module,\n",
        "            optimizer: torch.optim.Optimizer,\n",
        "            criterion: nn.Module,\n",
        "            batch_size: int = 64,\n",
        "            val_batch_size: int = 500,\n",
        "            use_cpu: bool = False,\n",
        "    ):\n",
        "        self.batch_size = batch_size\n",
        "        self.val_batch_size = val_batch_size  # We can use a bigger batch size for validation\n",
        "\n",
        "        self.device = torch.device(\"cpu\") if use_cpu else torch.accelerator.current_accelerator()\n",
        "        # The current accelerator automically detects CUDA/MPS/CPU\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        transforms = v2.Compose([\n",
        "            v2.ToImage(),\n",
        "            v2.ToDtype(torch.float32, scale=True),\n",
        "            v2.Normalize([0.5], [0.5]),\n",
        "            torch.flatten,\n",
        "        ])\n",
        "\n",
        "        train_set = datasets.MNIST(root='./data', train=True, transform=transforms, download=True)\n",
        "        val_set = datasets.MNIST(root='./data', train=False, transform=transforms, download=True)\n",
        "        self.train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "        self.val_loader = DataLoader(val_set, batch_size=val_batch_size, shuffle=False)\n",
        "        # We don't need to shuffle the validation set\n",
        "\n",
        "        self.model = model.to(self.device)  # The model must be on the same device\n",
        "        self.criterion = criterion.to(self.device)  # Required for some loss functions\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.model.train()\n",
        "\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        total_loss = 0\n",
        "\n",
        "        for data, target in tqdm(self.train_loader, desc=\"Training\", leave=False, disable=True):  # Disable on notebook\n",
        "            # We must move the data to the same device as the model\n",
        "            data = data.to(self.device)\n",
        "            target = target.to(self.device)\n",
        "            # We can also use non_blocking=True to speed up the transfer for large tensors\n",
        "            # data = data.to(self.device, non_blocking=True)\n",
        "            # but this is useful only for pinned memory transfers (CPU-to-GPU)\n",
        "            # In most cases, the improvement is negligible\n",
        "\n",
        "            predicted = self.model(data)\n",
        "            loss = self.criterion(predicted, target)\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            correct += (predicted.argmax(dim=1) == target).sum().item()\n",
        "            total += data.size(0)\n",
        "            total_loss += loss.item() * data.size(0)\n",
        "\n",
        "        return total_loss / total, correct / total\n",
        "\n",
        "    # @torch.no_grad()  # This is what you usually see in tutorials\n",
        "    @torch.inference_mode()  # This is the recommended way to do this\n",
        "    def val(self):\n",
        "        self.model.eval()\n",
        "\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        total_loss = 0\n",
        "\n",
        "        for data, target in tqdm(self.val_loader, desc=\"Validation\", leave=False, disable=True):  # Disable on notebook\n",
        "            data = data.to(self.device)\n",
        "            target = target.to(self.device)\n",
        "\n",
        "            predicted = self.model(data)\n",
        "            loss = self.criterion(predicted, target)\n",
        "\n",
        "            correct += (predicted.argmax(dim=1) == target).sum().item()\n",
        "            total += data.size(0)\n",
        "            total_loss += loss.item() * data.size(0)\n",
        "\n",
        "        return total_loss / total, correct / total\n",
        "\n",
        "    def run(self, epochs: int):\n",
        "        print(f\"Running {epochs} epochs\")\n",
        "        with tqdm(range(epochs), desc=\"Training\") as pbar:\n",
        "            for _ in pbar:\n",
        "                tr_loss, tr_acc = self.train()\n",
        "                va_loss, va_acc = self.val()\n",
        "                pbar.set_postfix(train_loss=tr_loss, train_acc=tr_acc, val_loss=va_loss, val_acc=va_acc)\n",
        "        print(\"Last validation accuracy: \", va_acc)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MmvtlxXKCy57"
      },
      "outputs": [],
      "source": [
        "def main(epochs: int, optimizer: str):\n",
        "    print(f\"Running {epochs} epochs with {optimizer} optimizer\")\n",
        "\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(28 * 28, 16),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(16, 10),\n",
        "    )\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    elif optimizer == \"sgd_momentum\":\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    elif optimizer == \"sgd_momentum_nesterov\":\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
        "    elif optimizer == \"sgd_momentum_nesterov_weight_decay\":\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True, weight_decay=0.001)\n",
        "    elif optimizer == \"adam\":\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    elif optimizer == \"adamw\":\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
        "    elif optimizer == \"rmsprop\":\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "    else:\n",
        "        raise NotImplementedError(f\"Optimizer {optimizer} not implemented\")\n",
        "\n",
        "    trainer = Trainer(model, optimizer, nn.CrossEntropyLoss())\n",
        "    trainer.run(epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyxKorl-Cy58"
      },
      "source": [
        "Recommended resources:\n",
        "* https://emiliendupont.github.io/2018/01/24/optimization-visualization/\n",
        "* The official documentation for each optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpdwRIFGCy58",
        "outputId": "7c0b39be-e5b3-4f29-bc37-0d409ab17f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 10 epochs with sgd optimizer\n",
            "Using device: cuda\n",
            "Running 10 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [03:25<00:00, 20.59s/it, train_acc=0.924, train_loss=0.266, val_acc=0.926, val_loss=0.261]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last validation accuracy:  0.9257\n",
            "\n",
            "Running 10 epochs with sgd_momentum optimizer\n",
            "Using device: cuda\n",
            "Running 10 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [03:27<00:00, 20.70s/it, train_acc=0.926, train_loss=0.254, val_acc=0.929, val_loss=0.243]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last validation accuracy:  0.9292\n",
            "\n",
            "Running 10 epochs with sgd_momentum_nesterov optimizer\n",
            "Using device: cuda\n",
            "Running 10 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [03:27<00:00, 20.76s/it, train_acc=0.926, train_loss=0.263, val_acc=0.927, val_loss=0.257]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last validation accuracy:  0.9266\n",
            "\n",
            "Running 10 epochs with sgd_momentum_nesterov_weight_decay optimizer\n",
            "Using device: cuda\n",
            "Running 10 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [03:26<00:00, 20.65s/it, train_acc=0.923, train_loss=0.271, val_acc=0.922, val_loss=0.269]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last validation accuracy:  0.922\n",
            "\n",
            "Running 10 epochs with adam optimizer\n",
            "Using device: cuda\n",
            "Running 10 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [03:27<00:00, 20.75s/it, train_acc=0.933, train_loss=0.228, val_acc=0.933, val_loss=0.228]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last validation accuracy:  0.933\n",
            "\n",
            "Running 10 epochs with adamw optimizer\n",
            "Using device: cuda\n",
            "Running 10 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [03:26<00:00, 20.70s/it, train_acc=0.93, train_loss=0.24, val_acc=0.93, val_loss=0.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last validation accuracy:  0.9299\n",
            "\n",
            "Running 10 epochs with rmsprop optimizer\n",
            "Using device: cuda\n",
            "Running 10 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [03:26<00:00, 20.60s/it, train_acc=0.883, train_loss=0.4, val_acc=0.872, val_loss=0.42]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last validation accuracy:  0.8716\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    main(10, \"sgd\")\n",
        "    main(10, \"sgd_momentum\")\n",
        "    main(10, \"sgd_momentum_nesterov\")\n",
        "    main(10, \"sgd_momentum_nesterov_weight_decay\")\n",
        "    main(10, \"adam\")\n",
        "    main(10, \"adamw\")\n",
        "    main(10, \"rmsprop\")\n",
        "\n",
        "# Engineering: Why do you think the training is so slow? Can you make it faster?\n",
        "# Science: Why do you think the results are not better? What can we do to improve them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0iUx9ZOCy59"
      },
      "source": [
        "## Excercises:\n",
        "\n",
        "You may start with excercise 3 if 1 and 2 prove to be too difficult. Implementing your own pipeline might bring you closer to the solution.\n",
        "\n",
        "1. Modify this pipeline in order to improve the training speed. Test various hypotheses. Starting with a simple pipeline allows you to make more focused progress in understanding the bottlenecks. Measuring the is the most important part of the process. Python multi-threading/multi-processing is not the right answer.\n",
        "2. Focus on increasing the accuracy of the model. You should be able to easily get 95% accuracy on the validation set.\n",
        "3. Implement your own pipeline from scratch. Implementing it yourself provides a better understanding. Do not be shackeled by this model.\n",
        "4. Try to get 98% accuracy on the validation set with all optimizers, using this pipeline. It is not very complicated.\n",
        "5. Try to get 98% with your pipeline.\n",
        "\n",
        "> !!! **Do not make training decisions based on the validation data! Otherwise you will risk overfitting!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQCtSITFyLNA"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fRjdQexyLNA"
      },
      "source": [
        "| All     | [beginner_pytorch/](https://github.com/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/beginner_pytorch) |\n",
        "|---------|-- |\n",
        "| Prev    | [Simple Training](https://github.com/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/beginner_pytorch/03_simple_training.ipynb) |\n",
        "| Current | [Optimizers](https://github.com/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/beginner_pytorch/04_optimizers.ipynb) |\n",
        "| Next    | [LR Schedulers](https://github.com/Tensor-Reloaded/AI-Learning-Hub/blob/main/resources/beginner_pytorch/05_lr_schedulers.ipynb) |"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}